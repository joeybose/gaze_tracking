{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Populating the interactive namespace from numpy and matplotlib\n"
     ]
    }
   ],
   "source": [
    "import time\n",
    "import dlib\n",
    "import csv\n",
    "import os\n",
    "import features\n",
    "import numpy as np\n",
    "import skimage.io\n",
    "import matplotlib.pyplot as plt\n",
    "import cPickle as pickle\n",
    "import itertools as it\n",
    "import more_itertools as mit\n",
    "from collections import namedtuple\n",
    "\n",
    "import multiprocessing\n",
    "%pylab inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "TRAINING_FOLDER = '/Users/vt/Code/Internal/lab-gaze-tracker/training_data/company-day-nov-6/'\n",
    "OUTPUT_CSV_FILE = 'gaze_vectors_with_failures_2.csv'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Gaze vector and failure extraction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Each image will have its gaze vector extracted for each face detected in the image.\n",
    "# Failures will also be reported (face_detection_error, left/right_pupil_error)\n",
    "#\n",
    "# Row Format:\n",
    "# file_path,failure1:failure2:failure3,x1,x2,...\n",
    "\n",
    "def dets_in_rois_generator(rois, frame):\n",
    "    for roi in rois:\n",
    "        y1 = roi.top() - 100\n",
    "        y2 = roi.bottom() + 100\n",
    "        x1 = roi.left() - 100\n",
    "        x2 = roi.right() + 100\n",
    "        for det in features.FaceDetection.calculate(frame[y1:y2, x1:x2].copy()):\n",
    "            yield det\n",
    "\n",
    "def file_to_gaze_vector_with_erorrs_csv_rows(file_path, rois=[]):\n",
    "    frame = skimage.io.imread(file_path)\n",
    "    \n",
    "    if not rois:\n",
    "        dets = features.FaceDetection.calculate(frame)\n",
    "        if not dets:\n",
    "            return ([], [(file_path, 'face_detection_error')])\n",
    "    else:\n",
    "        dets = list(dets_in_rois_generator(rois, frame))\n",
    "        if not dets:\n",
    "            return file_to_gaze_vector_with_erorrs_csv_rows(file_path, [])\n",
    "    \n",
    "    rows = []\n",
    "    \n",
    "    for det in dets:\n",
    "        failures = []\n",
    "\n",
    "        landmarks = features.FaceLandmarks.calculate(frame, det)\n",
    "        orientation = features.HeadOrientation.calculate(frame, landmarks)\n",
    "        eye_roi = features.EyeRegions.calculate(landmarks)\n",
    "        left_pupil = features.IrisFinder.calculate(frame, eye_roi.left)\n",
    "        right_pupil = features.IrisFinder.calculate(frame, eye_roi.right)\n",
    "        ellipses = features.EyeEllipses.calculate(landmarks)\n",
    "        \n",
    "        if left_pupil == ((0,0), 0):\n",
    "            failures.append('left_pupil_error')\n",
    "        if right_pupil == ((0,0), 0):\n",
    "            failures.append('right_pupil_error')\n",
    "\n",
    "        vector = features.GazeMatrix.calculate(\n",
    "            landmarks,\n",
    "            orientation,\n",
    "            ellipses,\n",
    "            left_pupil,\n",
    "            right_pupil\n",
    "        )\n",
    "\n",
    "        rows.append([file_path, ':'.join(failures)] + vector)\n",
    "        \n",
    "    # file_path,failure1:failure2:failure3,x1,x2,...\n",
    "    return (dets, rows)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Build file list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "rejected_dirs = (\n",
    "#     'back_left', 'back_right', 'back_center',\n",
    "#     'front_center', 'front_left', 'front_right',\n",
    "#     'p10', 'p11', 'p12', 'p13', 'p14', 'p15', 'p16', 'p17', 'p18',\n",
    "#     'p19', 'p20', 'p21', 'p22', 'p23', 'p9', 'p8', 'p7', 'p6', 'p5',\n",
    "#     'p4', 'p3', 'p2', 'p2-glasses'\n",
    ")\n",
    "training_files = []\n",
    "for root, dirs, files in os.walk(TRAINING_FOLDER):\n",
    "    filtered_files = (f for f in files if f != '.DS_Store')\n",
    "    for file_ in filtered_files:\n",
    "        training_files.append(os.path.join(root, file_))\n",
    "        \n",
    "    for rd in rejected_dirs:\n",
    "        if rd in dirs:\n",
    "            dirs.remove(rd)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Process files and extract feature and failures"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Note: The following process takes a while.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Time started: 1447186912.99\n",
      "Time ended: 1447188889.31\n"
     ]
    }
   ],
   "source": [
    "print \"Time started:\", time.time()\n",
    "\n",
    "out_file = open(OUTPUT_CSV_FILE, 'w')\n",
    "writer = csv.writer(out_file)\n",
    "tracker = dlib.correlation_tracker()\n",
    "rois = []\n",
    "for file_path in training_files:\n",
    "    (updated_rois, rows) = file_to_gaze_vector_with_erorrs_csv_rows(file_path, rois)\n",
    "    writer.writerows(rows)\n",
    "    rois = updated_rois\n",
    "    out_file.flush()\n",
    "\n",
    "print \"Time ended:\", time.time()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Dataset Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total number of files:\t4928\n",
      "Total vectors:\t\t5061\n",
      "Complete vectors:\t3796\n",
      "\n",
      "Left Pupil errors:\t18\n",
      "Right Pupil errors:\t23\n",
      "Face detection errors:\t1238\n",
      "\n",
      "Numer of multiple detections:  115\n"
     ]
    }
   ],
   "source": [
    "Sample = namedtuple('Sample', ['path','label','vector'])\n",
    "\n",
    "def map_file_path_to_number(file_path):\n",
    "    for label in LABELS:\n",
    "        if label in file_path:\n",
    "            return labels_to_number[label]\n",
    "    return -1\n",
    "\n",
    "def map_row_to_sample(csv_row):\n",
    "    return Sample(\n",
    "        path=row[0],\n",
    "        label=map_file_path_to_number(row[0]),\n",
    "        vector=[float(x) for x in row[2:]]\n",
    "    )\n",
    "\n",
    "def failures(rows):\n",
    "    for row in rows:\n",
    "        if row[1]:\n",
    "            for failure in row[1].split(':'):\n",
    "                yield failure\n",
    "\n",
    "vectors_dump_file = open(OUTPUT_CSV_FILE, 'rb')\n",
    "vectors_and_failures = list(csv.reader(vectors_dump_file))\n",
    "\n",
    "LABELS = ['top_left', 'top_right', 'bot_left', 'bot_right']\n",
    "labels_to_number = dict(zip(LABELS, range(len(LABELS))))\n",
    "samples = [map_row_to_sample(row) for row in vectors_and_failures if not row[1]]\n",
    "\n",
    "paths = [s.path for s in samples]\n",
    "detections_per_file_counts = [[x,paths.count(x)] for x in set(paths)]\n",
    "multiple_detections = [x for x in detections_per_file_counts if x[1] > 1]\n",
    "\n",
    "\n",
    "print \"Total number of files:\\t\", len(training_files)\n",
    "print \"Total vectors:\\t\\t\", len(vectors_and_failures)\n",
    "print \"Complete vectors:\\t\", len(samples) \n",
    "print \"\"\n",
    "print \"Left Pupil errors:\\t\", sum((1 for f in failures(vectors_and_failures) if f == 'left_pupil_error'))\n",
    "print \"Right Pupil errors:\\t\", sum((1 for f in failures(vectors_and_failures) if f == 'right_pupil_error'))\n",
    "print \"Face detection errors:\\t\", sum((1 for f in failures(vectors_and_failures) if f == 'face_detection_error'))\n",
    "print \"\"\n",
    "print \"Numer of multiple detections: \", len(multiple_detections)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
